{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30bfbf6e-a6cd-411a-b35a-d63d0247754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import SingleStage, DoubleStage, PromptToOutline  # Adjust if your dataset class is named differently\n",
    "from utils import calculate_perplexity, calculate_distinct_n\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3648d238-da26-475c-8f38-216677de72a4",
   "metadata": {},
   "source": [
    "Prompt to Outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e109a72a-36a4-46cf-b3d0-672a9963756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml') as file:\n",
    "    config = yaml.full_load(file)\n",
    "\n",
    "training_args = config['training_args']\n",
    "\n",
    "# Checkpoint directory\n",
    "checkpoint_dir = os.path.join(config['model']['save_path'], 'pto_stage')\n",
    "model_path = os.path.join(checkpoint_dir, 'model.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f2e0db3-244d-4042-8dbc-8865c1c993f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from checkpoint...\n"
     ]
    }
   ],
   "source": [
    "decoder_name = config['model']['decoder']\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(decoder_name, padding_side=\"left\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Loading model from checkpoint...\")\n",
    "    model = GPT2LMHeadModel.from_pretrained(checkpoint_dir, use_safetensors=True)\n",
    "else:\n",
    "    print(\"Initializing new model...\")\n",
    "    raise FileNotFoundError(f\"Checkpoint not found in {checkpoint_dir}. Ensure the checkpoint exists before resuming.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cd1c299-6537-4cfd-975a-6d94933bf208",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "model.resize_token_embeddings(len(tokenizer), mean_resizing=False)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aac6a8c3-ab5b-41ba-86fe-14a98fc271eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PromptToOutline(config['dataset']['test_path'], tokenizer)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8c922c6c-7a8b-46d4-b9d4-2f7a11df3b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs Shape: torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "sample_index = 12 # Change this index to sample a different example\n",
    "sample_data = train_dataset[sample_index]\n",
    "\n",
    "# Ensure 'input_ids' and 'attention_mask' are in the correct format\n",
    "if 'input_ids' in sample_data and 'attention_mask' in sample_data:\n",
    "    input_ids = sample_data['input_ids'].to(device)  # No need to unsqueeze, it's already 2D\n",
    "    attention_mask = sample_data['attention_mask'].to(device)  # Move to device\n",
    "else:\n",
    "    raise KeyError(\"'input_ids' or 'attention_mask' not found in sample_data\")\n",
    "\n",
    "# Check the shape of input_ids\n",
    "print(\"Input IDs Shape:\", input_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ebb50321-4fc6-4ec2-93d2-f6695c5b8284",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Use max_new_tokens to specify how many tokens to generate\n",
    "    generated_ids = model.generate(input_ids, attention_mask=attention_mask,  repetition_penalty=2.0, max_new_tokens=50, num_return_sequences=1, pad_token_id=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd4a30d9-4e1b-43e1-871b-125f4f6ade29",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "56a6ae9a-8b72-46e4-a7f6-db9032f7559b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:\n",
      " [ WP ] Everyone has a reaper . The further away it is , the longer you have left to live . Every day it inches a little bit closer , but it is always there . Except yours , which disappeared three weeks ago <SEP> shrieking twisting screaming tearing countless incredible technological achievements could never keep tied back white sweater expanding ever ethereal smoke trailing behind thousand thoughts crossed snake oil supplements many things ran lovely chest beneath great explosive conglomeration\n",
      "Generated Text:\n",
      " [ WP ] Everyone has a reaper . The further away it is , the longer you have left to live . Every day it inches a little bit closer , but it is always there . Except yours , which disappeared three weeks ago <SEP> shrieking twisting screaming tearing countless incredible technological achievements could never keep tied back white sweater expanding ever ethereal smoke trailing behind thousand thoughts crossed snake oil supplements many things ran lovely chest beneath great explosive conglomeration ” said jimmy wispy clouds swirled around us like tiny black specks floating small blue light began swirling dark cloud slowly rose giant red eyes stared straight ahead …. oh god ... '' mr rosssby started walking towards\n"
     ]
    }
   ],
   "source": [
    "print(\"Input Text:\\n\", tokenizer.decode(input_ids[0], skip_special_tokens=True))\n",
    "print(\"Generated Text:\\n\", generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3104eb2a-7cc5-4e26-a1e8-7f067f065ef9",
   "metadata": {},
   "source": [
    "Double Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3c34c634-6123-4f7d-8e95-d00d36a1cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml') as file:\n",
    "    config = yaml.full_load(file)\n",
    "\n",
    "training_args = config['training_args']\n",
    "\n",
    "# Checkpoint directory\n",
    "checkpoint_dir = os.path.join(config['model']['save_path'], 'double_stage')\n",
    "model_path = os.path.join(checkpoint_dir, 'model.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4aa6fdb5-fdf9-4d7b-a87c-4881a65eb08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from checkpoint...\n"
     ]
    }
   ],
   "source": [
    "decoder_name = config['model']['decoder']\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(decoder_name, padding_side=\"left\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Loading model from checkpoint...\")\n",
    "    model = GPT2LMHeadModel.from_pretrained(checkpoint_dir, use_safetensors=True)\n",
    "else:\n",
    "    print(\"Initializing new model...\")\n",
    "    raise FileNotFoundError(f\"Checkpoint not found in {checkpoint_dir}. Ensure the checkpoint exists before resuming.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55bc1326-b059-40f6-badf-960ab94ba815",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "model.resize_token_embeddings(len(tokenizer), mean_resizing=False)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da85059d-e655-450a-8c0a-524dc1918a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DoubleStage(config['dataset']['test_path'], tokenizer)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e299d3ce-7569-4331-a115-d764266ba788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs Shape: torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "sample_index = 10\n",
    "# Change this index to sample a different example\n",
    "sample_data = train_dataset[sample_index]\n",
    "\n",
    "# Ensure 'input_ids' and 'attention_mask' are in the correct format\n",
    "if 'input_ids' in sample_data and 'attention_mask' in sample_data:\n",
    "    input_ids = sample_data['input_ids'].to(device)  # No need to unsqueeze, it's already 2D\n",
    "    attention_mask = sample_data['attention_mask'].to(device)  # Move to device\n",
    "else:\n",
    "    raise KeyError(\"'input_ids' or 'attention_mask' not found in sample_data\")\n",
    "\n",
    "# Check the shape of input_ids\n",
    "print(\"Input IDs Shape:\", input_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "93c0d06a-6b6c-459c-a1c0-80718fa073ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Use max_new_tokens to specify how many tokens to generate\n",
    "    generated_ids = model.generate(input_ids, attention_mask=attention_mask, repetition_penalty=2.0,  max_new_tokens=46, num_return_sequences=1, pad_token_id=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "52fb74c2-4814-430f-b9e5-dd29e9d23eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5f7dc774-9cf6-4496-b653-67f1918922e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:\n",
      " [ WP ] A magical mirror shows your reflection and your future soulmate . You only see your reflection . <S> stand reading another old junky sci teen girl interrupted knick knacks decorated carnival music seemed carnival director walks “ ten dollars another idiot ten dollars another day start packing <SEP> It was just another day at the carnival . ” <newline> <newline> “ And it works ? I put the tent and everything in the back of my trailer with a skip in my step .\n",
      "Generated Text:\n",
      " [ WP ] A magical mirror shows your reflection and your future soulmate . You only see your reflection . <S> stand reading another old junky sci teen girl interrupted knick knacks decorated carnival music seemed carnival director walks “ ten dollars another idiot ten dollars another day start packing <SEP> It was just another day at the carnival . ” <newline> <newline> “ And it works ? I put the tent and everything in the back of my trailer with a skip in my step . The next morning , as she walked into her apartment after work on time to get some coffee from me while walking down an alleyway that night before heading out for lunch break-time when we were going home ; there wasn´t\n"
     ]
    }
   ],
   "source": [
    "print(\"Input Text:\\n\", tokenizer.decode(input_ids[0], skip_special_tokens=True))\n",
    "print(\"Generated Text:\\n\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e84849-591f-4767-9884-b01fd83374f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9563e74-8d1c-4936-9343-f25e348549ab",
   "metadata": {},
   "source": [
    "Single Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5ddf4a51-e6ed-4b5e-8073-7fe414246250",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml') as file:\n",
    "    config = yaml.full_load(file)\n",
    "\n",
    "training_args = config['training_args']\n",
    "\n",
    "# Checkpoint directory\n",
    "checkpoint_dir = os.path.join(config['model']['save_path'], 'single_stage')\n",
    "model_path = os.path.join(checkpoint_dir, 'model.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ab7d6892-1c55-4777-92b7-789199bfda58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from checkpoint...\n"
     ]
    }
   ],
   "source": [
    "decoder_name = config['model']['decoder']\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(decoder_name, padding_side=\"left\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Loading model from checkpoint...\")\n",
    "    model = GPT2LMHeadModel.from_pretrained(checkpoint_dir, use_safetensors=True)\n",
    "else:\n",
    "    print(\"Initializing new model...\")\n",
    "    raise FileNotFoundError(f\"Checkpoint not found in {checkpoint_dir}. Ensure the checkpoint exists before resuming.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f8943b88-db62-4452-baa7-65fb048174eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "model.resize_token_embeddings(len(tokenizer), mean_resizing=False)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ef5e8e52-6137-47dc-bf9e-08a97edd8488",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DoubleStage(config['dataset']['test_path'], tokenizer)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "02667a9e-7df1-4694-812c-ff4f96760b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs Shape: torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "sample_index = 5 # Change this index to sample a different example\n",
    "sample_data = train_dataset[sample_index]\n",
    "\n",
    "# Ensure 'input_ids' and 'attention_mask' are in the correct format\n",
    "if 'input_ids' in sample_data and 'attention_mask' in sample_data:\n",
    "    input_ids = sample_data['input_ids'].to(device)  # No need to unsqueeze, it's already 2D\n",
    "    attention_mask = sample_data['attention_mask'].to(device)  # Move to device\n",
    "else:\n",
    "    raise KeyError(\"'input_ids' or 'attention_mask' not found in sample_data\")\n",
    "\n",
    "# Check the shape of input_ids\n",
    "print(\"Input IDs Shape:\", input_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f3aa0a7b-5a72-4fd4-9802-9f36cfc25c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Use max_new_tokens to specify how many tokens to generate\n",
    "    generated_ids = model.generate(input_ids, attention_mask=attention_mask,  repetition_penalty=2.0, max_new_tokens=50, num_return_sequences=1, pad_token_id=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f867b62d-7fdd-464a-9942-d4ee0715a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f0c3cfe3-cf0e-4aa3-a5b3-3818fc1aadcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:\n",
      " [ TT ] `` Shut the dog up . '' <S> sides heaved one last breath skittish animal moved skinny animal circling rough sandy ground keep watch like blood trailed behind running circles around right away sir “ yes sir head officer yelled <SEP> The dog stopped its barking , and shifted its black eyes to me . <newline> <newline> “ GRUNT , ” the sound of my officer ’ s voice rang out , scaring the dog away . <newline> <newline> “ Grunt , get back in the jeep , were running off schedule , ”\n",
      "Generated Text:\n",
      " [ TT ] `` Shut the dog up . '' <S> sides heaved one last breath skittish animal moved skinny animal circling rough sandy ground keep watch like blood trailed behind running circles around right away sir “ yes sir head officer yelled <SEP> The dog stopped its barking , and shifted its black eyes to me . <newline> <newline> “ GRUNT , ” the sound of my officer ’ s voice rang out , scaring the dog away . <newline> <newline> “ Grunt , get back in the jeep , were running off schedule , ” I said as we got into our car with a loud screech that sounded just before it hit us on top speed at an old lady who was still not paying attention but she had no idea what happened next time for her husband or where he went to\n"
     ]
    }
   ],
   "source": [
    "print(\"Input Text:\\n\", tokenizer.decode(input_ids[0], skip_special_tokens=True))\n",
    "print(\"Generated Text:\\n\", generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2cc15c-a4ea-415f-925d-d1cfcb4d9713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5f1617-2205-42b3-81ad-75661534c9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8569c6-dd2b-4c61-9784-5dd384335edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab11386-16d3-4ac7-9f51-12dbfeab111f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
